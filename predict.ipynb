{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os,time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import models\n",
    "from torchvision import transforms as tfs\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path =\"./results\"\n",
    "resultpath = \"./pics\"\n",
    "modelpath = \"./mobilenet_model_100e.pth.tar\"\n",
    "class MobileNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MobileNet, self).__init__()\n",
    "\n",
    "        # Normal convolution block followed by Batchnorm (CONV_3x3-->BN-->Relu)\n",
    "        def conv_bn(inp, oup, stride):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        # Depthwise convolution block (CONV_BLK_3x3-->BN-->Relu-->CONV_1x1-->BN-->Relu)\n",
    "        def conv_dw(inp, oup, stride):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n",
    "                nn.BatchNorm2d(inp),\n",
    "                nn.ReLU(inplace=True),\n",
    "    \n",
    "                nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            conv_bn(  3,  32, 2), \n",
    "            conv_dw( 32,  64, 1),\n",
    "            conv_dw( 64, 128, 2),\n",
    "            conv_dw(128, 128, 1),\n",
    "            conv_dw(128, 256, 2),\n",
    "            conv_dw(256, 256, 1),\n",
    "            conv_dw(256, 512, 2),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 1024, 2),\n",
    "            conv_dw(1024, 1024, 1),\n",
    "            nn.AvgPool2d(7),\n",
    "        )\n",
    "        self.fc = nn.Linear(1024, 1000)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "batch_size = 64\n",
    "workers = 1\n",
    "epochs = 1\n",
    "print_freq = 100\n",
    "\n",
    "valdir = path\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "\n",
    "val_image_data =datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_image_data,\n",
    "    batch_size=batch_size, shuffle=False,\n",
    "    num_workers=workers, pin_memory=True)\n",
    "class_dicts = val_image_data.class_to_idx\n",
    "# print(class_dicts)\n",
    "# print(val_image_data.imgs)\n",
    "model = MobileNet()\n",
    "model = torch.load(modelpath)\n",
    "\n",
    "# switch to evaluate mode\n",
    "model.eval()\n",
    "def get_acc(output, label):\n",
    "    total = output.shape[0]\n",
    "    _, pred_label = output.max(1)\n",
    "    num_correct = (pred_label == label).sum().item()\n",
    "    return num_correct / total\n",
    "\n",
    "def evaluate(val_loader, model):\n",
    "    val_acc =0\n",
    "    for im, label in val_loader:\n",
    "        if torch.cuda.is_available():\n",
    "            im_val = Variable(im.cuda())  # (bs, 3, h, w)\n",
    "            label_val = Variable(label.cuda())  # (bs, h, w)\n",
    "        else:\n",
    "            im_val = Variable(im)\n",
    "            label_val = Variable(label)\n",
    "        # compute output\n",
    "        output = model(im_val)\n",
    "        # measure accuracy and record loss\n",
    "        val_acc +=get_acc(output,label_val)\n",
    "        # measure elapsed time\n",
    "        end = time.time()\n",
    "        print('acc {}'.format(val_acc/len(val_loader)))\n",
    "\n",
    "def tensor_to_PIL(tensor):\n",
    "    image = tensor.clone()\n",
    "    image = image.squeeze(0)\n",
    "    image = unloader(image)\n",
    "    return image\n",
    "\n",
    "def get_key (dict, value):\n",
    "    return [k for k, v in dict.items() if v == value]\n",
    "        \n",
    "def predict(data_loader,model):\n",
    "    data_acc =0\n",
    "#     print(\"dataloader length \"+str(len(data_loader)))\n",
    "    for image, imginfo in zip(data_loader,val_image_data.imgs):\n",
    "        im = image[0]\n",
    "        label = image[1]\n",
    "#         print(\"data_acc = {}\".format(data_acc))\n",
    "#         print(\"label is {}\".format(label))\n",
    "        if torch.cuda.is_available():\n",
    "            im_data = Variable(im.cuda())  # (bs, 3, h, w)\n",
    "            label_data = Variable(label.cuda())  # (bs, h, w)\n",
    "        else:\n",
    "            im_data = Variable(im)\n",
    "            label_data = Variable(label)\n",
    "        # compute output\n",
    "        output = model(im_data)\n",
    "        # measure accuracy and record loss\n",
    "        total = output.shape[0]\n",
    "        _, pred_label = output.max(1)\n",
    "#         for p in pred_label:\n",
    "#             print(\"p item {}\".format(p.item()))\n",
    "#         for l in label_data:\n",
    "#             print(\"l item {}\".format(l.item()))\n",
    "#         print(imginfo)\n",
    "#         print(pred_label.item())\n",
    "#         print(label_data.item())\n",
    "        count=0\n",
    "        for p,l,pic in zip(pred_label,label_data,im):\n",
    "            count+=1\n",
    "            if p!=l:\n",
    "                image1 = tfs.ToPILImage()(pic)\n",
    "#                 image1 = Image.fromarray(np.transpose(pic.cpu().detach().numpy(), (1, 2, 0)))\n",
    "                print(image1)\n",
    "                labelname = get_key(class_dicts,int(p))\n",
    "                labelname1 = get_key(class_dicts,int(l))\n",
    "                image1.save(resultpath+\"/pred_\"+labelname[0]+\"_\"+labelname1[0]+\"_\"+str(count)+\".jpg\")\n",
    "        num_correct = (pred_label == label_data).sum().item()\n",
    "        data_acc+= num_correct / total\n",
    "        # measure elapsed time\n",
    "        end = time.time()\n",
    "        print('acc {}'.format(data_acc/len(data_loader)))\n",
    "\n",
    "\n",
    "predict(val_loader,model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}